{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mpl_toolkits\n",
    "%matplotlib inline\n",
    "\n",
    "# chi-squared test with similar proportions\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "from scipy import stats\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import statsmodels.api as sm       \n",
    "\n",
    "from itertools import combinations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setActions = ['a1']\n",
    "# setResponse = [] #....\n",
    "# setEffect = ['e1', 'e2'] #.... \n",
    "\n",
    "## This function reads the artificially genereted tables from the designed csv\n",
    "def read_table(exp, row, freq):\n",
    "    r1 = pd.Series(row)[3:7].tolist();\n",
    "#     print(r1)\n",
    "    r2 =pd.Series(row)[7:11].tolist();\n",
    "#     print(r2)\n",
    "    r3 = pd.Series(row)[11:15].tolist();\n",
    "#     print(r3)\n",
    "    frame = { 'r1': r1, 'r2': r2, 'r3':r3 } \n",
    "    tempTable = pd.DataFrame(frame).T\n",
    "    # for each cells times a 'freq'\n",
    "    tempTable = tempTable*freq\n",
    "    return(tempTable)\n",
    "\n",
    "\n",
    "## This function reads the artificially genereted tables from the designed csv\n",
    "def create_one_response_table(response2effectTable, response):\n",
    "    oneResponseTable = response2effectTable\n",
    "    currentR = response\n",
    "\n",
    "    oneResponseTable.loc['total'] = pd.Series(oneResponseTable.sum())\n",
    "    oneResponseTable.loc['nonR'] = oneResponseTable.loc['total'] - oneResponseTable.loc[currentR]\n",
    "\n",
    "    oneResponseTableWithTotal = oneResponseTable\n",
    "    \n",
    "    for other_response in myResponses:\n",
    "        if other_response != currentR:\n",
    "            oneResponseTable = oneResponseTable.drop(other_response)\n",
    "    \n",
    "    oneResponseTable = oneResponseTable.drop('total')\n",
    "    return(oneResponseTable, oneResponseTableWithTotal)\n",
    "#     print(oneResponseTable)\n",
    "\n",
    "def checking_non_neg_assumptions(oneResponseTable, response2effectTableWithTotal):\n",
    "    # Checking assumptions\n",
    "    boolAssumptionTrue = True\n",
    "\n",
    "    # Assumption 1: For each expected cell, the number > 0\n",
    "    for aj in response2effectTableWithTotal.columns:\n",
    "        if response2effectTableWithTotal.at['total', aj] == 0:\n",
    "            boolAssumptionTrue = False\n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "    # TODO \n",
    "#     if !boolAssumptionTrue:\n",
    "#         print(\"NA\")\n",
    "\n",
    "    return(boolAssumptionTrue)\n",
    "\n",
    "\n",
    "def checking_80perc_expected_assumptions(expected):\n",
    "    # Assumption 2: At least 80% of expected cells >= 5 // test on the oneResponseTable\n",
    "    # TO DISCUSS!!! VERY DIFFICULT, checking the full table or checking the one response table. \n",
    "    return((expected > 0).sum(1).sum() >= (0.8 * 8))\n",
    "\n",
    "def chi2_cont_row(df):\n",
    "    stat, p, dof, expected = chi2_contingency(df, correction=True)\n",
    "#     print('dof=%d' % dof)\n",
    "#     print(expected)\n",
    "\n",
    "    # interpret test-statistic\n",
    "    prob = 0.95\n",
    "    critical = chi2.ppf(prob, dof)\n",
    "#     print('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\n",
    "\n",
    "#     if abs(stat) >= critical:\n",
    "#         print('Dependent (reject H0)')\n",
    "#     else:\n",
    "#         print('Independent (fail to reject H0)')\n",
    "\n",
    "\n",
    "    # interpret p-value\n",
    "    alpha = 1.0 - prob\n",
    "#     print('significance=%.3f, p=%.3f' % (alpha, p))\n",
    "#     if p <= alpha:\n",
    "#         print('Dependent (reject H0)')\n",
    "#     else:\n",
    "#         print('Independent (fail to reject H0)')\n",
    "    return stat, p, dof, expected \n",
    "\n",
    "def test_corrcoef():\n",
    "    a = np.array([\n",
    "        [1, 2, 3, 4],\n",
    "        [1, 3, 1, 4],\n",
    "        [8, 3, 8, 5],\n",
    "        [2, 3, 2, 1]])\n",
    "\n",
    "    r1, p1 = corrcoef(a)\n",
    "    r2, p2 = corrcoef_loop(a)\n",
    "\n",
    "    assert np.allclose(r1, r2)\n",
    "    assert np.allclose(p1, p2)\n",
    "    \n",
    "def calculate_number_of_significant_edges(oneResponseTable, currentR):\n",
    "    countEdgesDraw = 0\n",
    "    countZeroEdgesDraw = 0\n",
    "    countSigLessEdgesDraw = 0\n",
    "    countSigMoreEdgesDraw = 0\n",
    "    countdiffedges = 0\n",
    "    sharededges = 0\n",
    "    adjresidual = 2.57 \n",
    "    dfgfilter = 0.8\n",
    "    shortfull = table.iloc[0:3, 0:4]\n",
    "    maxtable = max(shortfull.max())\n",
    "    threshold = maxtable-(maxtable*dfgfilter)\n",
    "    \n",
    "    stat, p, dof, expected = chi2_cont_row(oneResponseTable)\n",
    "    \n",
    "    rtable = sm.stats.Table(oneResponseTable)     \n",
    "#         print(rtable.resid_pearson)\n",
    "#         print(rtable.standardized_resids)\n",
    "\n",
    "    subtable = pd.DataFrame(rtable.standardized_resids)\n",
    "#     print(subtable)\n",
    "    \n",
    "    expectedT = pd.DataFrame(expected, columns = oneResponseTable.columns, index = oneResponseTable.index)\n",
    "#     print(newTable)\n",
    "#     print(expectedT)\n",
    "\n",
    "    for aj in oneResponseTable.columns:\n",
    "        if (subtable.at[currentR,aj] < -adjresidual) or (subtable.at[currentR,aj] > adjresidual):\n",
    "            countEdgesDraw +=1\n",
    "            if(subtable.at[currentR,aj] < -adjresidual):\n",
    "                countSigLessEdgesDraw += 1\n",
    "            if (subtable.at[currentR,aj] > adjresidual) :\n",
    "                countSigMoreEdgesDraw += 1\n",
    "            if(oneResponseTable.at[currentR, aj] == 0):\n",
    "                countZeroEdgesDraw +=1\n",
    "#             if(oneResponseTable.at[currentR, aj] > threshold) and ((subtable.at[currentR,aj] <= adjresidual) or (subtable.at[currentR,aj] >= -adjresidual)):\n",
    "#                 countdiffedges += 1\n",
    "#             if(oneResponseTable.at[currentR, aj] <= threshold) and ((subtable.at[currentR,aj] > adjresidual) or (subtable.at[currentR,aj] < -adjresidual)):\n",
    "#                 countdiffedges += 1\n",
    "            if(oneResponseTable.at[currentR, aj] > threshold):\n",
    "                sharededges += 1\n",
    "    return(countEdgesDraw, countZeroEdgesDraw, countSigLessEdgesDraw, countSigMoreEdgesDraw, countdiffedges, sharededges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "header_list = [\"nEff\", \"nResp\", \"step\", \"c1\", \"c2\", \"c3\", \"c4\", \"c5\", \"c6\", \"c7\", \"c8\", \"c9\", \"c10\", \"c11\", \"c12\"]\n",
    "\n",
    "filenumber = 1\n",
    "n = 10\n",
    "for filenumber in range(filenumber, n):\n",
    "    file = 'Archive/pmf_tables_for_evaluation_'+str(filenumber)+'.csv'\n",
    "    expFullTable = pd.read_csv(file, ',',  names=header_list, encoding='latin1')\n",
    "    \n",
    "    #print(expFullTable.head())\n",
    "\n",
    "    columnRes = 'Responses'\n",
    "\n",
    "    expFullTable.count()\n",
    "    \n",
    "    # create 'table' from CSV\n",
    "    rowNumber = 1\n",
    "    freq = 100\n",
    "    test = read_table(expFullTable, expFullTable.iloc[rowNumber], freq)\n",
    "    # print(test)\n",
    "    \n",
    "    myResponses = {\"r1\", \"r2\", \"r3\"}\n",
    "    create_one_response_table(test, 'r1')\n",
    "    \n",
    "    #calculate_number_of_significant_edges(test, 'r1')\n",
    "    countRow = 0 \n",
    "\n",
    "    for i, row in expFullTable.iterrows():\n",
    "        if(countRow % 1000 == 0):\n",
    "            print(countRow)\n",
    "            countRow+=1\n",
    "    \n",
    "        orgtable = read_table(expFullTable, row, freq)\n",
    "        table = orgtable.copy()\n",
    "    #     print(\"This is table\")\n",
    "    #     print(table)\n",
    "    #     print(\"----\")\n",
    "    \n",
    "        totNumEdgesOfOurs = 0\n",
    "        totNumZeroEdgesOurs = 0\n",
    "        totNumSigMoreEdgesOurs = 0\n",
    "        totNumDiffEdges = 0\n",
    "        totNumSharedEdges = 0\n",
    "    \n",
    "        bool_Assumption_all_responses = True;\n",
    "    \n",
    "        pvalues = list()\n",
    "        numEdges = list()\n",
    "        numZeroEdges = list()\n",
    "        numSigMoreEdges = list()\n",
    "        numDiffEdges = list()\n",
    "        numSharedEdges = list()\n",
    "    \n",
    "        # For each response \n",
    "        for response in myResponses:\n",
    "            oneResponseTable, oneResponseTableWithTotal = create_one_response_table(table, response)\n",
    "    #         print(\"This is one response:\")\n",
    "    #         print(oneResponseTable)\n",
    "        \n",
    "        \n",
    "            # Test assumptions\n",
    "            bool_Assumption_Single_Response = checking_non_neg_assumptions(oneResponseTable, oneResponseTableWithTotal)\n",
    "            if(bool_Assumption_Single_Response):\n",
    "                stat, p, dof, expected = chi2_cont_row(oneResponseTable)\n",
    "            \n",
    "                if (checking_80perc_expected_assumptions(expected)):\n",
    "                    pvalues.append(p)\n",
    "                    num, numZero, numSigLess, numSigMore, numDiff, numShared = calculate_number_of_significant_edges(oneResponseTable, response)\n",
    "                    numEdges.append(num)\n",
    "                    numZeroEdges.append(numZero)\n",
    "                    numSigMoreEdges.append(numSigMore)\n",
    "                    numDiffEdges.append(numDiff)\n",
    "                    numSharedEdges.append(numShared)\n",
    "                \n",
    "                else:\n",
    "                    bool_Assumption_all_responses = False;\n",
    "            \n",
    "            else:\n",
    "                ## Chi-test's assumptions do not hold. We do not compute anything\n",
    "                bool_Assumption_all_responses = False;\n",
    "            \n",
    "      \n",
    "        expFullTable.at[i, 'ourNumEdges'] = str('NA')\n",
    "        expFullTable.at[i, 'ourNumZeroEdges'] = str('NA')\n",
    "        expFullTable.at[i, 'ourNumPosEdges'] = str('NA')\n",
    "        expFullTable.at[i, 'ourNumSigMoreEdges'] = str('NA')\n",
    "        expFullTable.at[i, 'DiffEdges'] = str('NA')\n",
    "        expFullTable.at[i, 'SharedEdges'] = str('NA')\n",
    "        if(bool_Assumption_all_responses):\n",
    "        \n",
    "            p_adjusted_list = multipletests(pvalues, alpha=.05, method='bonferroni')\n",
    "            for index, p_adjusted in enumerate(p_adjusted_list[0]):\n",
    "    #             print(p_adjusted)\n",
    "                if(p_adjusted):\n",
    "                    totNumEdgesOfOurs += numEdges[index]\n",
    "                    totNumZeroEdgesOurs += numZeroEdges[index]\n",
    "                    totNumSigMoreEdgesOurs += numSigMoreEdges[index]\n",
    "                    totNumDiffEdges += numDiffEdges[index]\n",
    "                    totNumSharedEdges += numSharedEdges[index]\n",
    "        \n",
    "            expFullTable.at[i, 'ourNumEdges'] = str(totNumEdgesOfOurs)\n",
    "            expFullTable.at[i, 'ourNumZeroEdges'] = str(totNumZeroEdgesOurs)\n",
    "            expFullTable.at[i, 'ourNumPosEdges'] = str(totNumEdgesOfOurs - totNumZeroEdgesOurs)\n",
    "            expFullTable.at[i, 'ourNumSigMoreEdges'] = str(totNumSigMoreEdgesOurs)\n",
    "            expFullTable.at[i, 'DiffEdges'] = str(totNumDiffEdges)\n",
    "            expFullTable.at[i, 'SharedEdges'] = str(totNumSharedEdges)\n",
    "    #     else:\n",
    "    #         expFullTable.at[i, 'ourNumEdges'] = str('NA')\n",
    "    #         expFullTable.at[i, 'ourNumZeroEdges'] = str('NA')\n",
    "    #         expFullTable.at[i, 'ourNumPosEdges'] = str('NA')\n",
    "    #         expFullTable.at[i, 'ourNumSigMoreEdges'] = str('NA')\n",
    "    \n",
    "        dfgfilter = 0.8\n",
    "        shortfull = table.iloc[0:3, 0:4]\n",
    "        maxtable = max(shortfull.max())\n",
    "        threshold = maxtable-(maxtable*dfgfilter)\n",
    "        dfgNumEdges80 = shortfull[shortfull > threshold].count().sum();\n",
    "        dfgNumEdges100 = (orgtable > 0).sum(1).sum();\n",
    "        #     print(dfgNumEdges.tolist())\n",
    "  \n",
    "        expFullTable.at[i, 'dfgNumEdges80'] = dfgNumEdges80\n",
    "        expFullTable.at[i, 'dfgNumEdges100'] = dfgNumEdges100\n",
    "    \n",
    "    # standard deviation of each column (effect) and the average for all four columns\n",
    "    expFullTable['sdE1'] = expFullTable[['c1','c5','c9']].std(axis=1)\n",
    "    expFullTable['sdE2'] = expFullTable[['c2','c6','c10']].std(axis=1)\n",
    "    expFullTable['sdE3'] = expFullTable[['c3','c7','c11']].std(axis=1)\n",
    "    expFullTable['sdE4'] = expFullTable[['c4','c8','c12']].std(axis=1)\n",
    "    expFullTable['sda'] = expFullTable[['sdE1','sdE2','sdE3','sdE4']].mean(axis=1)\n",
    "    # round sda to 4 digits\n",
    "    expFullTable = expFullTable.round({'sda': 4})\n",
    "\n",
    "    #print(expFullTable.loc[1])\n",
    "    file2 = \"Archive/pmf_tables_for_evaluation_res_80per_\"+str(filenumber)+\".csv\"\n",
    "    expFullTable.to_csv(file2, \",\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### for clean data ####\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "\n",
    "# path = 'Archive/'\n",
    "\n",
    "# all_files = glob.glob(os.path.join(path, 'pmf_tables_for_evaluation_res_80per_*.csv'))\n",
    "\n",
    "# df_merged = (pd.read_csv(f, sep=',') for f in all_files)\n",
    "# df_from_each_file = (pd.read_csv(f, sep=',') for f in all_files)\n",
    "# df_merged = pd.concat(df_from_each_file, ignore_index=True)\n",
    "# df_merged.to_csv('Archive/Merged/clean_80per.csv')\n",
    "\n",
    "# TestEvalTableClean = pd.read_csv('Archive/Merged/clean_80per.csv', ',', encoding='latin1')\n",
    "\n",
    "#### for noisy data ####\n",
    "TestEvalTableNoise = pd.read_csv('Archiven/pmf_tables_for_evaluation_res_1.csv', ';', encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### choose data clean or noisy ####\n",
    "TestEvalTable = TestEvalTableNoise\n",
    "#print(TestEvalTable.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TestEvalTable['OurEdgesNZ'] = TestEvalTable['ourNumEdges'] - TestEvalTable['ourNumZeroEdges']\n",
    "TestEvalTable['OurEdgesNZWZ'] = TestEvalTable['OurEdgesNZ'].fillna(0)\n",
    "TestEvalTable['DiffEdges80'] = (TestEvalTable['OurEdgesNZWZ'] - TestEvalTable['SharedEdges']) + (TestEvalTable['dfgNumEdges80'] - TestEvalTable['SharedEdges'])\n",
    "TestEvalTable['DiffEdges100'] = (TestEvalTable['OurEdgesNZWZ'] - TestEvalTable['SharedEdges']) + (TestEvalTable['dfgNumEdges100'] - TestEvalTable['SharedEdges'])\n",
    "TestEvalTable.loc[TestEvalTable.OurEdgesNZWZ == 0, \"SharedEdges\"] = 0\n",
    "TestEvalTable.loc[TestEvalTable.OurEdgesNZWZ == 0, \"DiffEdges80\"] = TestEvalTable['dfgNumEdges80']\n",
    "TestEvalTable.loc[TestEvalTable.OurEdgesNZWZ == 0, \"DiffEdges100\"] = TestEvalTable['dfgNumEdges100']\n",
    "#print(TestEvalTable.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sda     dfgNumEdges80\n",
      "0.0000  3.0               4\n",
      "        4.0               0\n",
      "        5.0               0\n",
      "        6.0              24\n",
      "        7.0               0\n",
      "        8.0               0\n",
      "        9.0              24\n",
      "        10.0              0\n",
      "        11.0              0\n",
      "        12.0              4\n",
      "0.0491  3.0               6\n",
      "        4.0               0\n",
      "        5.0               0\n",
      "        6.0              30\n",
      "        7.0               9\n",
      "        8.0               9\n",
      "        9.0               6\n",
      "        10.0              3\n",
      "        11.0              3\n",
      "        12.0              0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Koorn004\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sda     dfgNumEdges100\n",
      "0.0000  6.0                1\n",
      "        7.0                0\n",
      "        8.0                0\n",
      "        9.0               18\n",
      "        10.0               0\n",
      "        11.0               0\n",
      "        12.0              37\n",
      "0.0491  6.0                0\n",
      "        7.0                0\n",
      "        8.0                0\n",
      "        9.0                0\n",
      "        10.0              18\n",
      "        11.0              18\n",
      "        12.0              30\n",
      "0.0520  6.0                0\n",
      "        7.0                0\n",
      "        8.0                0\n",
      "        9.0               12\n",
      "        10.0              24\n",
      "        11.0              24\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Koorn004\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sda     OurEdgesNZWZ\n",
      "0.0000  0.0             56\n",
      "        1.0              0\n",
      "        2.0              0\n",
      "        3.0              0\n",
      "        4.0              0\n",
      "        5.0              0\n",
      "        6.0              0\n",
      "        7.0              0\n",
      "        8.0              0\n",
      "        9.0              0\n",
      "        10.0             0\n",
      "        11.0             0\n",
      "        12.0             0\n",
      "0.0491  0.0              2\n",
      "        1.0             20\n",
      "        2.0             36\n",
      "        3.0              6\n",
      "        4.0              2\n",
      "        5.0              0\n",
      "        6.0              0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Koorn004\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "#round up sda\n",
    "TestEvalTable = TestEvalTable.round({'sda': 4})\n",
    "# tables for (bubble) charts + tables (like table 5)\n",
    "Bdfg80 = pd.crosstab(TestEvalTable['sda'], TestEvalTable['dfgNumEdges80'], margins=True, margins_name=\"Total\")\n",
    "BUBDFG80 = Bdfg80.drop('Total', axis = 1)\n",
    "BUBDFG80 = BUBDFG80.stack()\n",
    "print(BUBDFG80.head(n=20))\n",
    "#print(Bdfg80.head(n=20))\n",
    "BUBDFG80.to_csv('Archiven/Merged/BUBDFG80_noise_r.csv')\n",
    "#Bdfg80.to_csv('Archive/Merged/Bdfg80_noise_r.csv')\n",
    "\n",
    "Bdfg100 = pd.crosstab(TestEvalTable['sda'], TestEvalTable['dfgNumEdges100'], margins=True, margins_name=\"Total\")\n",
    "BUBDFG100 = Bdfg100.drop('Total', axis = 1)\n",
    "BUBDFG100 = BUBDFG100.stack()\n",
    "print(BUBDFG100.head(n=20))\n",
    "#print(Bdfg100.head(n=20))\n",
    "BUBDFG100.to_csv('Archiven/Merged/BUBDFG100_noise_r.csv')\n",
    "#Bdfg100.to_csv('Archive/Merged/Bdfg100_noise_r.csv')\n",
    "\n",
    "Bo = pd.crosstab(TestEvalTable['sda'], TestEvalTable['OurEdgesNZWZ'], margins=True, margins_name=\"Total\")\n",
    "BUBour = Bo.drop('Total', axis = 1)\n",
    "BUBour = BUBour.stack()\n",
    "print(BUBour.head(n=20))\n",
    "#print(Bo.head(n=20))\n",
    "BUBour.to_csv('Archiven/Merged/BUBour_noise_r.csv')\n",
    "#Bo.to_csv('Archive/Merged/Bo_noise_r.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bs = pd.crosstab(TestEvalTable['sda'], TestEvalTable['SharedEdges'], margins=True, margins_name=\"Total\")\n",
    "BUBshare = Bs.drop('Total', axis = 1)\n",
    "BUBshare = BUBshare.stack()\n",
    "# print(Bs.head(n=20))\n",
    "# print(BUBshare.head(n=20))\n",
    "Bs.to_csv('Archiven/Merged/Bshared_noise.csv')\n",
    "\n",
    "Bd100 = pd.crosstab(TestEvalTable['sda'], TestEvalTable['DiffEdges100'], margins=True, margins_name=\"Total\")\n",
    "BUBdiff100 = Bd100.drop('Total', axis = 1)\n",
    "BUBdiff100 = BUBdiff100.stack()\n",
    "# print(Bd100.head(n=20))\n",
    "# print(BUBdiff100.head(n=20))\n",
    "Bd100.to_csv('Archiven/Merged/Bdifferent100_noise.csv')\n",
    "\n",
    "Bd80 = pd.crosstab(TestEvalTable['sda'], TestEvalTable['DiffEdges80'], margins=True, margins_name=\"Total\")\n",
    "BUBdiff80 = Bd80.drop('Total', axis = 1)\n",
    "BUBdiff80 = BUBdiff80.stack()\n",
    "# print(Bd80.head(n=20))\n",
    "# print(BUBdiff80.head(n=20))\n",
    "Bd80.to_csv('Archiven/Merged/Bdifferent80_noise.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
